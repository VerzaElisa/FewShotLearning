{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from CNN.utility import train_routine\n",
    "from ds_creation.ds_utility import get_file_count, get_other_class\n",
    "from ds_creation.split_config import phisical_split\n",
    "from ds_creation.plot_utility import process_metrics\n",
    "from prototypical.train.train_setup import train\n",
    "from prototypical.model.loader import get_samples\n",
    "\n",
    "\n",
    "\n",
    "SPLIT_PERC = {'train': 0.8, 'val': 0.2}\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "DATA_DIR = os.path.join('data', 'mammals_calls', 'data')\n",
    "TEST_DIR = os.path.join('data', 'mammals_calls_test')\n",
    "SPLIT_DIR = os.path.join('data', 'mammals_calls', 'splits', 'custom')\n",
    "AUDIO_DIR = os.path.join('data', 'audio')\n",
    "MODELS_METRICS_DIR = os.path.join(\"models_metrics\")\n",
    "CNN_CACHE_DIR = os.path.join(\"data_cache\", \"CNN\")\n",
    "\n",
    "PATIENCE = 5\n",
    "TO_TRAIN = False\n",
    "FROM_START = True\n",
    "os.makedirs(MODELS_METRICS_DIR, exist_ok=True)\n",
    "os.makedirs(SPLIT_DIR, exist_ok=True)\n",
    "    \n",
    "h = 164\n",
    "w = 397\n",
    "\n",
    "seed = 2025\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Eseguo lo split fisico dei file solo la prima volta per dividere i file in train e test\n",
    "FIRST_RUN = False\n",
    "if FIRST_RUN:\n",
    "    perc = 1-TEST_SPLIT\n",
    "    phisical_split(DATA_DIR, perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e007666",
   "metadata": {},
   "source": [
    "Vengono divise le specie in tre gruppi:\n",
    "* Quelle per il training della CNN, hanno più di 1000 sample, le restanti classi formeranno la classe other\n",
    "* Quelle per il training della Prototypical, hanno tra i 1000 ed i 100 sample\n",
    "* Quelle per il test della Prototypical, hanno meno di 100 sample \n",
    "\n",
    "Così vengono creati i file che serviranno alla prototypical per splittare le classi tra train, validation e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4310d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = get_file_count(DATA_DIR)\n",
    "\n",
    "CNN_training = count_df[count_df['file_count'] >= 1000]['species'].tolist()\n",
    "proto_training = count_df[(count_df['file_count'] <= 1000) & (count_df['file_count'] >= 100)]['species'].tolist()\n",
    "proto_test = count_df[count_df['file_count'] < 100]['species'].tolist()\n",
    "\n",
    "random.shuffle(proto_training)\n",
    "split_idx = int(len(proto_training) * SPLIT_PERC['train'])\n",
    "proto_train = proto_training[:split_idx]\n",
    "proto_val = proto_training[split_idx:]\n",
    "print(len(proto_train), len(proto_val), len(proto_test))\n",
    "with open(os.path.join(SPLIT_DIR, 'test.txt'), 'w') as f:\n",
    "    for species in proto_test:\n",
    "        f.write(f\"{species}\\n\")\n",
    "with open(os.path.join(SPLIT_DIR, 'train.txt'), 'w') as f:\n",
    "    for species in proto_train:\n",
    "        f.write(f\"{species}\\n\")\n",
    "with open(os.path.join(SPLIT_DIR, 'val.txt'), 'w') as f:\n",
    "    for species in proto_val:\n",
    "        f.write(f\"{species}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a13ca2",
   "metadata": {},
   "source": [
    "Viene fisicamente generata la classe other, contenente i files di tutte le altre classi che hanno meno di 1000 sample.\n",
    "Viene quindi avviato il training della CNN su queste classi con uno split train/val 80/20 per stabilire il numero di epoche ottimale per l'addestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df_truncated = get_file_count(DATA_DIR)\n",
    "count_df_truncated = count_df_truncated[count_df_truncated['file_count'] < 999]\n",
    "\n",
    "other_species_list = count_df_truncated['species'].tolist()\n",
    "print(f'Other total files: {count_df_truncated[\"file_count\"].sum()}, species count: {count_df_truncated.shape}, species: {other_species_list}')\n",
    "get_other_class(DATA_DIR, other_species_list)\n",
    "\n",
    "count_df = get_file_count(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_ds, history = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (0, 0), cardinality=1000, subfolder='31-10_training', from_start=FROM_START, to_train=TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_training_date = '14-10'\n",
    "process_metrics(count_df, 13, os.path.join(MODELS_METRICS_DIR, f'{curr_training_date}_training'), MODELS_METRICS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15c4db",
   "metadata": {},
   "source": [
    "## Proto Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0385d1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 splits with 4 classes each.\n",
      "Training started.\n",
      "Epoch 1 started.\n",
      "support shape: (4, 5, 164, 397, 3), query shape: (4, 3, 164, 397, 3)\n",
      "x shape: (12, 96), y shape: (4, 96)\n",
      "support shape: (4, 5, 164, 397, 3), query shape: (4, 3, 164, 397, 3)\n",
      "x shape: (12, 96), y shape: (4, 96)\n",
      "support shape: (4, 5, 164, 397, 3), query shape: (4, 3, 164, 397, 3)\n",
      "x shape: (12, 96), y shape: (4, 96)\n",
      "Epoch 1 ended.\n",
      "Epoch 2, Loss: 6.384324073791504, Accuracy: 0.6583332419395447, Val Loss: 1.345668911933899, Val Accuracy: 0.6305556297302246\n",
      "Saving new best model with accuracy: 0.6305556\n",
      "Epoch 2 started.\n",
      "Epoch 2 ended.\n",
      "Epoch 3, Loss: 1.0188957452774048, Accuracy: 0.5416666865348816, Val Loss: 1.065984845161438, Val Accuracy: 0.6000000238418579\n",
      "Epoch 3 started.\n",
      "Epoch 3 ended.\n",
      "Epoch 4, Loss: 0.9542425274848938, Accuracy: 0.5749999284744263, Val Loss: 0.9351992011070251, Val Accuracy: 0.7092592716217041\n",
      "Saving new best model with accuracy: 0.7092593\n",
      "Epoch 4 started.\n",
      "Epoch 4 ended.\n",
      "Epoch 5, Loss: 0.8383702039718628, Accuracy: 0.6916667222976685, Val Loss: 0.9104282855987549, Val Accuracy: 0.6796297430992126\n",
      "Epoch 5 started.\n",
      "Epoch 5 ended.\n",
      "Epoch 6, Loss: 0.7231295108795166, Accuracy: 0.7250000238418579, Val Loss: 0.9229627251625061, Val Accuracy: 0.6657408475875854\n",
      "Epoch 6 started.\n",
      "Epoch 6 ended.\n",
      "Epoch 7, Loss: 0.6776704788208008, Accuracy: 0.75, Val Loss: 1.2031234502792358, Val Accuracy: 0.5620370507240295\n",
      "Epoch 7 started.\n",
      "Epoch 7 ended.\n",
      "Epoch 8, Loss: 0.6823650598526001, Accuracy: 0.7583333253860474, Val Loss: 1.0416609048843384, Val Accuracy: 0.6166666150093079\n",
      "Epoch 8 started.\n",
      "Epoch 8 ended.\n",
      "Epoch 9, Loss: 0.6090785264968872, Accuracy: 0.7416666746139526, Val Loss: 1.186119556427002, Val Accuracy: 0.6592592597007751\n",
      "No improvement for 5 epochs. Early stopping triggered.\n",
      "Early stopping triggered!\n",
      "Training ended.\n",
      "Training succeed!\n",
      "Training took: 0.0 h 0.0 min 32.5586998462677 sec\n"
     ]
    }
   ],
   "source": [
    "way = 4\n",
    "support = 5\n",
    "query = 3\n",
    "config = {\n",
    "    \"data.dataset\": \"mammals_calls\",\n",
    "    \"data.split\": \"custom\",\n",
    "    \"data.train_way\": way,\n",
    "    \"data.train_support\": support,\n",
    "    \"data.train_query\": query,\n",
    "    \"data.test_way\": way,\n",
    "    \"data.test_support\": support,\n",
    "    \"data.test_query\": query,\n",
    "    \"data.episodes\": 10,\n",
    "    \"data.gpu\": 0,\n",
    "    \"data.cuda\":True,\n",
    "    \"model.x_dim\": \"164,397,3\",\n",
    "    \"model.z_dim\": 64,\n",
    "    \"train.epochs\": 50,\n",
    "    'train.optim_method': \"Adam\",\n",
    "    \"train.lr\": 0.001,\n",
    "    \"train.patience\": 5,\n",
    "    \"model.save_path\": 'data_cache/proto/test_mammals_calls.keras'\n",
    "}\n",
    "\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90271556",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = proto_val + proto_train + proto_test\n",
    "n_support_dict = {curr_class: len(os.listdir(os.path.join(DATA_DIR, curr_class))) for curr_class in classes}\n",
    "results = get_samples(classes, n_support_dict, {'w':w, 'h':h, 'c':3}, os.path.join('data_cache', 'proto', 'test_mammals_calls.keras'), DATA_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
