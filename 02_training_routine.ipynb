{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e77f32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from CNN.utility import train_routine\n",
    "from ds_creation.ds_utility import get_file_count, get_other_class\n",
    "from ds_creation.split_config import phisical_split\n",
    "from ds_creation.plot_utility import process_metrics\n",
    "from prototypical.train.train_setup import train\n",
    "\n",
    "\n",
    "\n",
    "SPLIT_PERC = {'train': 0.8, 'val': 0.2}\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "DATA_DIR = os.path.join('data', 'mammals_calls', 'data')\n",
    "TEST_DIR = os.path.join('data', 'mammals_calls_test')\n",
    "SPLIT_DIR = os.path.join('data', 'mammals_calls', 'splits', 'custom')\n",
    "AUDIO_DIR = os.path.join('data', 'audio')\n",
    "MODELS_METRICS_DIR = os.path.join(\"models_metrics\")\n",
    "CNN_CACHE_DIR = os.path.join(\"data_cache\", \"CNN\")\n",
    "\n",
    "PATIENCE = 5\n",
    "TO_TRAIN = False\n",
    "FROM_START = True\n",
    "os.makedirs(MODELS_METRICS_DIR, exist_ok=True)\n",
    "os.makedirs(SPLIT_DIR, exist_ok=True)\n",
    "    \n",
    "h = 164\n",
    "w = 397\n",
    "\n",
    "seed = 2025\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Eseguo lo split fisico dei file solo la prima volta per dividere i file in train e test\n",
    "FIRST_RUN = False\n",
    "if FIRST_RUN:\n",
    "    perc = 1-TEST_SPLIT\n",
    "    phisical_split(DATA_DIR, perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e007666",
   "metadata": {},
   "source": [
    "Vengono divise le specie in tre gruppi:\n",
    "* Quelle per il training della CNN, hanno più di 1000 sample, le restanti classi formeranno la classe other\n",
    "* Quelle per il training della Prototypical, hanno tra i 1000 ed i 100 sample\n",
    "* Quelle per il test della Prototypical, hanno meno di 100 sample \n",
    "\n",
    "Così vengono creati i file che serviranno alla prototypical per splittare le classi tra train, validation e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4310d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = get_file_count(DATA_DIR)\n",
    "\n",
    "CNN_training = count_df[count_df['file_count'] >= 1000]['species'].tolist()\n",
    "proto_training = count_df[(count_df['file_count'] <= 1000) & (count_df['file_count'] >= 100)]['species'].tolist()\n",
    "proto_test = count_df[count_df['file_count'] < 100]['species'].tolist()\n",
    "\n",
    "random.shuffle(proto_training)\n",
    "split_idx = int(len(proto_training) * SPLIT_PERC['train'])\n",
    "proto_train = proto_training[:split_idx]\n",
    "proto_val = proto_training[split_idx:]\n",
    "print(len(proto_train), len(proto_val), len(proto_test))\n",
    "with open(os.path.join(SPLIT_DIR, 'test.txt'), 'w') as f:\n",
    "    for species in proto_test:\n",
    "        f.write(f\"{species}\\n\")\n",
    "with open(os.path.join(SPLIT_DIR, 'train.txt'), 'w') as f:\n",
    "    for species in proto_train:\n",
    "        f.write(f\"{species}\\n\")\n",
    "with open(os.path.join(SPLIT_DIR, 'val.txt'), 'w') as f:\n",
    "    for species in proto_val:\n",
    "        f.write(f\"{species}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a13ca2",
   "metadata": {},
   "source": [
    "Viene fisicamente generata la classe other, contenente i files di tutte le altre classi che hanno meno di 1000 sample.\n",
    "Viene quindi avviato il training della CNN su queste classi con uno split train/val 80/20 per stabilire il numero di epoche ottimale per l'addestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df_truncated = get_file_count(DATA_DIR)\n",
    "count_df_truncated = count_df_truncated[count_df_truncated['file_count'] < 999]\n",
    "\n",
    "other_species_list = count_df_truncated['species'].tolist()\n",
    "print(f'Other total files: {count_df_truncated[\"file_count\"].sum()}, species count: {count_df_truncated.shape}, species: {other_species_list}')\n",
    "get_other_class(DATA_DIR, other_species_list)\n",
    "\n",
    "count_df = get_file_count(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_ds, history = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (0, 0), cardinality=1000, subfolder='14-10_training', from_start=FROM_START, to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23691333",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmax(history.history['val_accuracy']) + 1\n",
    "print(f'Best epoch: {best_epoch}, val_accuracy: {history.history[\"val_accuracy\"][best_epoch-1]}, accuracy: {history.history[\"accuracy\"][best_epoch-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_training_date = '14-10'\n",
    "process_metrics(count_df, 13, os.path.join(MODELS_METRICS_DIR, f'{curr_training_date}_training'), MODELS_METRICS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data.dataset\": \"mammals_calls\",\n",
    "    \"data.split\": \"custom\",\n",
    "    \"data.train_way\": 4,\n",
    "    \"data.train_support\": 2,\n",
    "    \"data.train_query\": 3,\n",
    "    \"data.test_way\": 4,\n",
    "    \"data.test_support\": 2,\n",
    "    \"data.test_query\": 3,\n",
    "    \"data.episodes\": 10,\n",
    "    \"data.gpu\": 0,\n",
    "    \"data.cuda\":True,\n",
    "    \"model.x_dim\": \"164,397,3\",\n",
    "    \"model.z_dim\": 64,\n",
    "    \"train.epochs\": 50,\n",
    "    'train.optim_method': \"Adam\",\n",
    "    \"train.lr\": 0.001,\n",
    "    \"train.patience\": 5,\n",
    "    \"model.save_path\": 'data_cache/proto/test_mammals_calls.keras'\n",
    "}\n",
    "\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_preprocess_image(img_path, sizes):\n",
    "    \"\"\"\n",
    "    Load and return preprocessed image.\n",
    "    Args:\n",
    "        img_path (str): path to the image on disk.\n",
    "    Returns (Tensor): preprocessed image\n",
    "    \"\"\"\n",
    "    w, h, _ = sizes\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, [h, w])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image.numpy()\n",
    "\n",
    "\n",
    "def embedding(support, w_h_c, model_dir):\n",
    "    w, h, c = w_h_c\n",
    "    n_support = len(support)\n",
    "    print(n_support)\n",
    "    # merge support and query to forward through encoder\n",
    "    model = tf.keras.models.load_model(model_dir)\n",
    "    z = []\n",
    "    for cat in support:\n",
    "        cat = tf.reshape(cat, [1, w, h, c])\n",
    "        z.append(model(cat))\n",
    "    z = tf.concat(z, axis=0)\n",
    "    # Prototypes are means of n_support examples\n",
    "    print(z.shape)\n",
    "    print(type(z))\n",
    "    z_prototypes = tf.math.reduce_mean(z, axis=1)\n",
    "    return z_prototypes\n",
    "\n",
    "def get_samples(classes, n_support_dict, w_h_c, model_dir):\n",
    "    embedding_dict = {}\n",
    "    for curr_class in classes:\n",
    "        n_support = n_support_dict[curr_class]\n",
    "        main_dir = os.path.join(DATA_DIR, curr_class)\n",
    "        files = os.listdir(main_dir)\n",
    "        selected_files = random.sample(files, n_support)\n",
    "        class_embeddings = []\n",
    "        for i_img in range(n_support):\n",
    "            curr_img = os.path.join(main_dir, selected_files[i_img])\n",
    "            class_embeddings.append(load_and_preprocess_image(curr_img, w_h_c))\n",
    "        embedding_dict[curr_class] = class_embeddings\n",
    "    embedding_df = pd.DataFrame(list(embedding_dict.items()), columns=['class', 'embeddings'])\n",
    "    embedding_df['embeddings'] = embedding_df['embeddings'].apply(lambda x: embedding(x, w_h_c, model_dir))  \n",
    "\n",
    "    return embedding_df\n",
    "classes = proto_val + proto_train\n",
    "n_support_dict = {curr_class: len(os.listdir(os.path.join(DATA_DIR, curr_class))) for curr_class in classes}\n",
    "results = get_samples(classes, n_support_dict, (w, h, 3), os.path.join('data_cache', 'proto', 'test_mammals_calls.keras'))\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_euclidian_dists(x, y):\n",
    "    \"\"\"\n",
    "    Calculate euclidian distance between two 3D tensors.\n",
    "\n",
    "    Args:\n",
    "        x (tf.Tensor):\n",
    "        y (tf.Tensor):\n",
    "\n",
    "    Returns (tf.Tensor): 2-dim tensor with distances.\n",
    "\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    m = y.shape[0]\n",
    "    x = tf.tile(tf.expand_dims(x, 1), [1, m, 1])\n",
    "    y = tf.tile(tf.expand_dims(y, 0), [n, 1, 1])\n",
    "    return tf.reduce_mean(tf.math.pow(x - y, 2), 2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
