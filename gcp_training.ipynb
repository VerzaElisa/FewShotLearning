{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e79f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = '../dataset_creation'\n",
    "md_path = 'metadata'\n",
    "ds_path = 'dataset'\n",
    "spec_path = 'spectrograms/'\n",
    "cp_path = 'checkpoints'\n",
    "saved_model_path = 'saved_model'\n",
    "\n",
    "# seed per la riproducibilità\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "if not os.path.exists(cp_path):\n",
    "    os.makedirs(cp_path)\n",
    "if not os.path.exists(saved_model_path):\n",
    "    os.makedirs(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8238c885-6dcd-4a9a-96b8-f12847e1b430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51cc1d-a71d-4399-876b-219427e7a56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76312 files belonging to 12 classes.\n",
      "Using 61050 files for training.\n",
      "Found 76312 files belonging to 12 classes.\n",
      "Using 15262 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Declare constants\n",
    "IMAGE_HEIGHT = 328\n",
    "IMAGE_WIDTH = 794\n",
    "BATCH_SIZE = 16\n",
    "N_CHANNELS = 3\n",
    "N_CLASSES = 12\n",
    "\n",
    "# Make a dataset containing the training spectrograms\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             directory=spec_path,\n",
    "                                             shuffle=True,\n",
    "                                             color_mode='rgb',\n",
    "                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                             subset=\"training\",\n",
    "                                             seed=0)\n",
    "# Make a dataset containing the validation spectrogram\n",
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             directory=spec_path,\n",
    "                                             shuffle=True,\n",
    "                                             color_mode='rgb',\n",
    "                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "                                             subset=\"validation\",\n",
    "                                             seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3149f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe Bowhead Whale: 2553 elementi\n",
      "Classe Common Dolphin: 1175 elementi\n",
      "Classe Fin, Finback Whale: 13272 elementi\n",
      "Classe Humpback Whale: 6279 elementi\n",
      "Classe Killer Whale: 2386 elementi\n",
      "Classe Long-Finned Pilot Whale: 1684 elementi\n",
      "Classe Pantropical Spotted Dolphin: 1679 elementi\n",
      "Classe Sperm Whale: 42634 elementi\n",
      "Classe Spinner Dolphin: 1757 elementi\n",
      "Classe Walrus: 683 elementi\n",
      "Classe Weddell Seal: 1352 elementi\n",
      "Classe White-sided Dolphin: 857 elementi\n"
     ]
    }
   ],
   "source": [
    "# Ottieni la lista delle classi\n",
    "class_names = train_dataset.class_names\n",
    "\n",
    "# Conta i file per ogni classe nella directory degli spettrogrammi\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(spec_path, class_name)\n",
    "    num_files = len([f for f in os.listdir(class_dir) if f.endswith('.png')])\n",
    "    print(f\"Classe {class_name}: {num_files} elementi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc816e7b-2026-4cf0-a228-680b775a6ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint frequency: 11448 batches\n"
     ]
    }
   ],
   "source": [
    "# Function to prepare our datasets for modelling\n",
    "def prepare(ds, augment=False):\n",
    "    # Define our one transformation\n",
    "    rescale = tf.keras.Sequential([tf.keras.layers.Rescaling(1./255)])\n",
    "    flip_and_rotate = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        tf.keras.layers.RandomRotation(0.2)\n",
    "    ])\n",
    "    \n",
    "    # Apply rescale to both datasets and augmentation only to training\n",
    "    ds = ds.map(lambda x, y: (rescale(x, training=True), y))\n",
    "    if augment: ds = ds.map(lambda x, y: (flip_and_rotate(x, training=True), y))\n",
    "    return ds\n",
    "\n",
    "train_dataset = prepare(train_dataset, augment=False)\n",
    "valid_dataset = prepare(valid_dataset, augment=False)\n",
    "\n",
    "batches = len(train_dataset)\n",
    "checkpoint_freq = batches*3\n",
    "print(f\"checkpoint frequency: {checkpoint_freq} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be806c7-d01d-4e83-b1d2-a19e77b659b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "def create_model():\n",
    "    initializer = tf.keras.initializers.GlorotNormal(seed=42)\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu', kernel_initializer=initializer))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax', kernel_initializer=initializer))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d6ee68-6472-4ef8-96e0-c0fc48195e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749550690.816114    1438 service.cc:152] XLA service 0x72dbe80044c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1749550690.816150    1438 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2025-06-10 10:18:11.123062: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1749550691.861342    1438 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-06-10 10:18:13.136902: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[16,64,82,198]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,82,198]{3,2,1,0} %bitcast.9062, f32[64,32,3,3]{3,2,1,0} %bitcast.7488, f32[64]{0} %bitcast.9102), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_4_1/convolution\" source_file=\"/home/elisaverza_gm/mmd/.mmd/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-10 10:18:13.493812: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.12 = (f32[16,128,41,99]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,41,99]{3,2,1,0} %bitcast.9322, f32[128,64,3,3]{3,2,1,0} %bitcast.7620, f32[128]{0} %bitcast.9362), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_5_1/convolution\" source_file=\"/home/elisaverza_gm/mmd/.mmd/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   2/3816\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:15\u001b[0m 67ms/step - accuracy: 0.1094 - loss: 4.2488   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749550699.418562    1438 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3815/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8861 - loss: 0.4299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 10:22:32.993677: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[9,64,82,198]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,32,82,198]{3,2,1,0} %bitcast.9062, f32[64,32,3,3]{3,2,1,0} %bitcast.7488, f32[64]{0} %bitcast.9102), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_4_1/convolution\" source_file=\"/home/elisaverza_gm/mmd/.mmd/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-10 10:22:33.090476: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.12 = (f32[9,128,41,99]{3,2,1,0}, u8[0]{0}) custom-call(f32[9,64,41,99]{3,2,1,0} %bitcast.9322, f32[128,64,3,3]{3,2,1,0} %bitcast.7620, f32[128]{0} %bitcast.9362), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_5_1/convolution\" source_file=\"/home/elisaverza_gm/mmd/.mmd/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3816/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8861 - loss: 0.4299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 10:22:38.879608: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[16,64,82,198]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,82,198]{3,2,1,0} %bitcast.897, f32[64,32,3,3]{3,2,1,0} %bitcast.904, f32[64]{0} %bitcast.906), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_4_1/convolution\" source_file=\"/home/elisaverza_gm/mmd/.mmd/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-10 10:22:39.225791: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.12 = (f32[16,128,41,99]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,41,99]{3,2,1,0} %bitcast.956, f32[128,64,3,3]{3,2,1,0} %bitcast.963, f32[128]{0} %bitcast.965), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_5_1/convolution\" source_file=\"/home/elisaverza_gm/mmd/.mmd/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-10 10:23:39.662040: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.11 = (f32[14,64,82,198]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,32,82,198]{3,2,1,0} %bitcast.897, f32[64,32,3,3]{3,2,1,0} %bitcast.904, f32[64]{0} %bitcast.906), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_4_1/convolution\" source_file=\"/home/elisaverza_gm/mmd/.mmd/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
      "2025-06-10 10:23:39.968686: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=0} for conv %cudnn-conv-bias-activation.12 = (f32[14,128,41,99]{3,2,1,0}, u8[0]{0}) custom-call(f32[14,64,41,99]{3,2,1,0} %bitcast.956, f32[128,64,3,3]{3,2,1,0} %bitcast.963, f32[128]{0} %bitcast.965), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_5_1/conv2d_5_1/convolution\" source_file=\"/home/elisaverza_gm/mmd/.mmd/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3816/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 84ms/step - accuracy: 0.8862 - loss: 0.4298 - val_accuracy: 0.5859 - val_loss: 7.9534\n",
      "Epoch 2/50\n",
      "\u001b[1m3816/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 83ms/step - accuracy: 0.9778 - loss: 0.0773 - val_accuracy: 0.9771 - val_loss: 0.2612\n",
      "Epoch 3/50\n",
      "\u001b[1m3816/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 82ms/step - accuracy: 0.9836 - loss: 0.0586 - val_accuracy: 0.9781 - val_loss: 0.0841\n",
      "Epoch 4/50\n",
      "\u001b[1m3816/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 84ms/step - accuracy: 0.9880 - loss: 0.0441 - val_accuracy: 0.9663 - val_loss: 0.3528\n",
      "Epoch 5/50\n",
      "\u001b[1m3816/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 82ms/step - accuracy: 0.9895 - loss: 0.0368 - val_accuracy: 0.9886 - val_loss: 0.0734\n",
      "Epoch 6/50\n",
      "\u001b[1m3816/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 83ms/step - accuracy: 0.9919 - loss: 0.0292 - val_accuracy: 0.9790 - val_loss: 0.1521\n",
      "Epoch 7/50\n",
      "\u001b[1m3816/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 84ms/step - accuracy: 0.9918 - loss: 0.0278 - val_accuracy: 0.9787 - val_loss: 0.5848\n",
      "Epoch 8/50\n",
      "\u001b[1m3816/3816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 84ms/step - accuracy: 0.9914 - loss: 0.0327 - val_accuracy: 0.9653 - val_loss: 0.2116\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.RMSprop(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "cp_cb = tf.keras.callbacks.ModelCheckpoint(filepath=Path(cp_path, 'recovery_weights.weights.h5'), save_weights_only=True, save_freq=checkpoint_freq)\n",
    "log_cb = tf.keras.callbacks.CSVLogger(\"history.csv\", append=True)\n",
    "\n",
    "history = model.fit(train_dataset, \n",
    "                    epochs=50, \n",
    "                    validation_data=valid_dataset, \n",
    "                    callbacks=[es_cb, cp_cb, log_cb]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4232c8e-07d9-4b21-bbe2-ad48d4da6c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 0.211576, final accuracy: 0.965339\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(valid_dataset, verbose=0)\n",
    "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df325ab2-a602-4602-addb-25d392e8903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights(Path(saved_model_path, '001_cnn_weights.weights.h5'))\n",
    "model.save(Path(saved_model_path, '001_cnn_model.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5f918-616c-481b-9e0c-4d7d0bac6624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mmd-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
