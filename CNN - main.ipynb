{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22efa032",
   "metadata": {},
   "source": [
    "## Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfa9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from CNN.utility import train_routine\n",
    "from CNN.loader import load_dataset, get_split\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "SPLIT_PERC = {'train': 0.8, 'val': 0.2}\n",
    "DATA_DIR = os.path.join('data', 'mammals_calls_grey')\n",
    "AUDIO_DIR = os.path.join('data', 'audio')\n",
    "TO_TRAIN = False\n",
    "h = 164\n",
    "w = 397\n",
    "\n",
    "seed = 2025\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88298a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = [f.path for f in os.scandir(DATA_DIR) if f.is_dir()]\n",
    "data_info = {}\n",
    "for subfolder in subfolders:\n",
    "    species_name = os.path.basename(subfolder)\n",
    "    file_count = len([f for f in os.listdir(subfolder) if os.path.isfile(os.path.join(subfolder, f))])\n",
    "    data_info[species_name] = file_count\n",
    "count_df = pd.DataFrame(list(data_info.items()), columns=['species', 'file_count'])\n",
    "count_df = count_df.sort_values(by='file_count', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_thousands = count_df[count_df['file_count'] > 1000]\n",
    "count_hundreds = count_df[(count_df['file_count'] > 100) & (count_df['file_count'] < 1000)]\n",
    "count_tens = count_df[count_df['file_count'] < 100]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(count_thousands['species'], count_thousands['file_count'], color=\"#87CEEB\")\n",
    "plt.bar(count_hundreds['species'], count_hundreds['file_count'], color='#00688B')\n",
    "plt.bar(count_tens['species'], count_tens['file_count'], color=\"#191970\")\n",
    "plt.xlabel('Species')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Log Scaled Number of Spectrograms')\n",
    "plt.yscale(\"log\")\n",
    "plt.title('Number of Spectrograms per Species')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Total number of species: {count_df.shape[0]}')\n",
    "print(count_thousands)\n",
    "print(f'Number of species with more than 1000 spectrograms: {count_thousands.shape[0]}')\n",
    "print(f'Number of species with more than 100 but less than 1000 spectrograms: {count_hundreds.shape[0]}')\n",
    "print(f'Number of species with less than 100 spectrograms: {count_tens.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_extractor(row, chunk_size):\n",
    "    try:\n",
    "        signal, sr = librosa.load(row['audio_files'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading audio file {row['audio_files']}: {e}\")\n",
    "        row['chunk_list'] = []\n",
    "        return row\n",
    "    chunk_size = chunk_size * sr\n",
    "    mfcc_chunks = []\n",
    "    i = 1\n",
    "    \n",
    "    for start in range(0, len(signal), sr):\n",
    "        i += 1\n",
    "        end = start + chunk_size\n",
    "        y_chunk = signal[start:end]\n",
    "        \n",
    "        if len(y_chunk) < chunk_size:\n",
    "            print(f\"Last chunk too short ({len(y_chunk)}<{chunk_size}), stopping.\")\n",
    "            break  \n",
    "        mfcc = librosa.feature.mfcc(y=y_chunk, sr=sr, n_mfcc=50)\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "\n",
    "        mfcc_chunks.append(mfcc_mean)\n",
    "    row['chunk_list'] = mfcc_chunks\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1700\n",
    "audio_files = {}\n",
    "for species in count_thousands['species']:\n",
    "    curr_path = os.path.join(AUDIO_DIR, species)\n",
    "    audio_files[species] = [os.path.join(curr_path, f) for f in os.listdir(curr_path) if f.endswith('.wav')]\n",
    "# creare una permutazione casuale di n elementi\n",
    "for species in audio_files.keys():\n",
    "    sampled_files = random.sample(audio_files[species], min(n, len(audio_files[species])))\n",
    "    audio_files[species] = sampled_files\n",
    "\n",
    "\n",
    "audio_df = pd.DataFrame(list(audio_files.items()), columns=['species', 'audio_files'])\n",
    "audio_df = audio_df.explode('audio_files').reset_index(drop=True)\n",
    "\n",
    "audio_df = audio_df.apply(mfcc_extractor, axis=1, chunk_size=2)\n",
    "audio_df_exploded = audio_df.explode('chunk_list').reset_index(drop=True)\n",
    "\n",
    "print(f'Different species in audio dataset: {audio_df_exploded[\"species\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c05948",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Different species in audio dataset: {audio_df_exploded[\"species\"].unique()}')\n",
    "# stampare la lunghezza della lista contenuta in 'chunk_list' per ogni riga del dataframe\n",
    "print(audio_df_exploded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e778cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminare le righe con liste vuote in 'chunk_list'\n",
    "audio_df_exploded_clean = audio_df_exploded.dropna(axis=0, subset=['chunk_list'])\n",
    "valid_chunks = audio_df_exploded_clean['chunk_list']\n",
    "valid_chunks = valid_chunks[valid_chunks.apply(lambda x: isinstance(x, np.ndarray) and len(x) == 50)]\n",
    "\n",
    "# Converti in matrice\n",
    "mfcc_matrix = np.array(valid_chunks.tolist())\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "    \n",
    "x_transformed = tsne.fit_transform(mfcc_matrix)\n",
    "tsne_df = pd.DataFrame(np.column_stack((x_transformed, audio_df_exploded_clean[\"species\"])), columns=['X', 'Y', \"Targets\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df.loc[:, \"Targets\"] = tsne_df.Targets.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec328e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "g = sns.FacetGrid(data=tsne_df, hue='Targets', height=8)\n",
    "g.map(plt.scatter, 'X', 'Y').add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe20307",
   "metadata": {},
   "source": [
    "## Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_CACHE_DIR = os.path.join(\"data_cache\", \"CNN\")\n",
    "MODELS_METRICS_DIR = os.path.join(\"models_metrics\")\n",
    "PATIENCE = 3\n",
    "if not os.path.exists(MODELS_METRICS_DIR):\n",
    "    os.makedirs(MODELS_METRICS_DIR)\n",
    "\n",
    "split_perc = {'train': 0.8, 'val': 0.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca453a",
   "metadata": {},
   "source": [
    "Training della CNN classica con le classi che contengono piÃ¹ di 1000 sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ec4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_classes_1000 = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (0, 0), to_train=TO_TRAIN, cardinality=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba605c51",
   "metadata": {},
   "source": [
    "Si ripete il training aggiungendo 10 classi per volta in ordine decrescente in numero di sample contenuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fino a classe 23\n",
    "n_classes_plus_10 = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (n_classes_1000, 10), to_train=TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fino a classe 33\n",
    "n_classes_plus_20 = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (n_classes_plus_10, 10), to_train=TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaab8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fino a classe 43\n",
    "n_classes_plus_30 = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (n_classes_plus_20, 10), to_train=TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fino all'ultima classe\n",
    "n_classes_plus_rem = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (n_classes_plus_30, 10), to_train=TO_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a359d3",
   "metadata": {},
   "source": [
    "## Output Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f8376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_metrics(row, all_classes_df, metrics_list):\n",
    "    for metric in metrics_list:\n",
    "        class_num = row['index']\n",
    "        col_name = rf'{class_num}_{metric}'\n",
    "        class_metrics = all_classes_df[col_name]\n",
    "        row[metric] = class_metrics\n",
    "    return row\n",
    "\n",
    "def process_metrics(n_classes, training_date):\n",
    "    all_classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, f'{training_date}_training', f'{n_classes}_CNN_metrics.csv'))\n",
    "    all_classes_df = all_classes_df.loc[:, all_classes_df.columns.str.match(r'^\\d')]\n",
    "    last_epoch_metrics = all_classes_df.iloc[-1]\n",
    "\n",
    "    classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, f'{training_date}_training', f'{n_classes}_label_to_index.csv'))\n",
    "\n",
    "    metrics_list = ['precision', 'recall', 'f1-score', 'support']\n",
    "    classes_df = classes_df.apply(get_class_metrics, axis=1, all_classes_df=last_epoch_metrics, metrics_list=metrics_list)\n",
    "    classes_df['label'] = classes_df['label'].apply(lambda x: ' '.join(x.split(' ')[:2]) if len(x) > 20 else x)\n",
    "    classes_df.to_csv(os.path.join(MODELS_METRICS_DIR, f'{training_date}_merged_metrics', f'{n_classes}_merged_metrics.csv'), index=False)\n",
    "\n",
    "def metrics_plot_builder(metrics_df):\n",
    "    metrics_list = ['precision', 'recall', 'f1-score']\n",
    "    f = 1\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    for metric in metrics_list:\n",
    "        axs = plt.subplot(2, 2, f)\n",
    "        axs.bar(metrics_df['label'], metrics_df[metric], color=\"#87CEEB\")\n",
    "        for i, (metric_value, support) in enumerate(zip(metrics_df[metric], metrics_df['support'])):\n",
    "            label_pos = metric_value - (metric_value/2) if metric_value > 0 else metric_value + 0.02\n",
    "            plt.text(i, label_pos, f'n:{int(support)}', ha='center', va='bottom', fontsize=9, rotation=90)\n",
    "        axs.set_xlabel('Class')\n",
    "        axs.tick_params(axis='x', rotation=90)\n",
    "        axs.set_ylabel(metric.capitalize())\n",
    "        axs.set_title(f'{metric.capitalize()} per Class (ordered by Support - descending)')\n",
    "        \n",
    "        f += 1\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2bb6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_training_date = '01-09'\n",
    "process_metrics(n_classes_1000, curr_training_date)\n",
    "process_metrics(n_classes_plus_10, curr_training_date)\n",
    "process_metrics(n_classes_plus_20, curr_training_date)\n",
    "process_metrics(n_classes_plus_30, curr_training_date)\n",
    "process_metrics(n_classes_plus_rem, curr_training_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682cdca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_metrics_date = '01-09_merged_metrics'\n",
    "classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, curr_metrics_date, f'{n_classes_1000}_merged_metrics.csv'))\n",
    "classes_df_sorted = classes_df.sort_values(by='support', ascending=False)\n",
    "fig = metrics_plot_builder(classes_df_sorted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_metrics_date = '01-09_merged_metrics'\n",
    "classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, curr_metrics_date, f'{n_classes_plus_10}_merged_metrics.csv'))\n",
    "classes_df_sorted = classes_df.sort_values(by='support', ascending=False)\n",
    "fig = metrics_plot_builder(classes_df_sorted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_metrics_date = '01-09_merged_metrics'\n",
    "classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, curr_metrics_date, f'{n_classes_plus_20}_merged_metrics.csv'))\n",
    "classes_df_sorted = classes_df.sort_values(by='support', ascending=False)\n",
    "fig = metrics_plot_builder(classes_df_sorted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4983e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_metrics_date = '01-09_merged_metrics'\n",
    "classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, curr_metrics_date, f'{n_classes_plus_30}_merged_metrics.csv'))\n",
    "classes_df_sorted = classes_df.sort_values(by='support', ascending=False)\n",
    "fig = metrics_plot_builder(classes_df_sorted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_metrics_date = '01-09_merged_metrics'\n",
    "classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, curr_metrics_date, f'{n_classes_plus_rem}_merged_metrics.csv'))\n",
    "classes_df_sorted = classes_df.sort_values(by='support', ascending=False)\n",
    "fig = metrics_plot_builder(classes_df_sorted)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
