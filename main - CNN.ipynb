{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22efa032",
   "metadata": {},
   "source": [
    "## Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6cfa9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-25 15:08:45.239493: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-25 15:08:45.308849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-25 15:08:46.635075: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs found: 1\n",
      "GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "GPUs found: 1\n",
      "GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from CNN.utility import train_routine\n",
    "from ds_creation.ds_utility import get_file_count, get_other_class\n",
    "from ds_creation.plot_utility import process_metrics, process_audio_files, tsne_calc\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "SPLIT_PERC = {'train': 0.8, 'val': 0.2}\n",
    "DATA_DIR = os.path.join('data', 'mammals_calls', 'data')\n",
    "AUDIO_DIR = os.path.join('data', 'audio')\n",
    "MODELS_METRICS_DIR = os.path.join(\"models_metrics\")\n",
    "\n",
    "h = 164\n",
    "w = 397\n",
    "\n",
    "seed = 2025\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88298a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 species  file_count\n",
      "28                           Sperm_Whale       34107\n",
      "37                    Fin,_Finback_Whale       10617\n",
      "50                                 other        5931\n",
      "38                        Humpback_Whale        5023\n",
      "6     Short-Finned_(Pacific)_Pilot_Whale        2129\n",
      "3                          Bowhead_Whale        2044\n",
      "19                          Killer_Whale        1908\n",
      "2                           Bearded_Seal        1892\n",
      "48                       Spinner_Dolphin        1405\n",
      "18               Long-Finned_Pilot_Whale        1347\n",
      "20           Pantropical_Spotted_Dolphin        1343\n",
      "35                    Bottlenose_Dolphin        1288\n",
      "39                          Weddell_Seal        1081\n",
      "40                        Common_Dolphin         940\n",
      "16                   White-sided_Dolphin         685\n",
      "24                                Walrus         546\n",
      "13                       Clymene_Dolphin         488\n",
      "10                      Fraser's_Dolphin         370\n",
      "32                    False_Killer_Whale         318\n",
      "29                       Striped_Dolphin         304\n",
      "51                   West_Indian_Manatee         257\n",
      "23                             Ross_Seal         243\n",
      "14                  Northern_Right_Whale         240\n",
      "27              Grampus,_Risso's_Dolphin         144\n",
      "4                        Harbor_Porpoise         136\n",
      "34                           Minke_Whale         133\n",
      "26              Atlantic_Spotted_Dolphin         131\n",
      "0                          Dusky_Dolphin         131\n",
      "8   Long_Beaked_(Pacific)_Common_Dolphin         128\n",
      "7                           Leopard_Seal         123\n",
      "49                   Beluga,_White_Whale         101\n",
      "12                    Melon_Headed_Whale          94\n",
      "41                  White-beaked_Dolphin          88\n",
      "5                             Gray_Whale          84\n",
      "25                             Harp_Seal          61\n",
      "22                  Southern_Right_Whale          48\n",
      "30           Boutu,_Amazon_River_Dolphin          42\n",
      "46                           Ribbon_Seal          39\n",
      "36                   Heaviside's_Dolphin          26\n",
      "11                       Dall's_Porpoise          16\n",
      "15                 Rough-Toothed_Dolphin          15\n",
      "17                          Spotted_Seal          14\n",
      "33                      Irawaddy_Dolphin          11\n",
      "21                               Narwhal          10\n",
      "45                           Ringed_Seal          10\n",
      "43               Juan_Fernandez_Fur_Seal           7\n",
      "44                        Tucuxi_Dolphin           5\n",
      "42                           Hooded_Seal           4\n",
      "9                              Sea_Otter           3\n",
      "1                       Finless_Porpoise           2\n",
      "47                      Steller_Sea_Lion           2\n",
      "31                  New_Zealand_Fur_Seal           1\n"
     ]
    }
   ],
   "source": [
    "count_df = get_file_count(DATA_DIR)\n",
    "print(count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_thousands = count_df[count_df['file_count'] > 1000]\n",
    "count_hundreds = count_df[(count_df['file_count'] > 100) & (count_df['file_count'] < 1000)]\n",
    "count_tens = count_df[count_df['file_count'] < 100]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(count_thousands['species'], count_thousands['file_count'], color=\"#87CEEB\")\n",
    "plt.bar(count_hundreds['species'], count_hundreds['file_count'], color='#00688B')\n",
    "plt.bar(count_tens['species'], count_tens['file_count'], color=\"#191970\")\n",
    "plt.xlabel('Species')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Log Scaled Number of Spectrograms')\n",
    "plt.yscale(\"log\")\n",
    "plt.title('Number of Spectrograms per Species')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Total number of species: {count_df.shape[0]}')\n",
    "print(count_thousands)\n",
    "print(f'Number of species with more than 1000 spectrograms: {count_thousands.shape[0]}')\n",
    "print(f'Number of species with more than 100 but less than 1000 spectrograms: {count_hundreds.shape[0]}')\n",
    "print(f'Number of species with less than 100 spectrograms: {count_tens.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c05948",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df_exploded, mfcc_matrix = process_audio_files(count_df['species'].tolist(), AUDIO_DIR, MODELS_METRICS_DIR)\n",
    "print(f'Different species in audio dataset: {audio_df_exploded[\"species\"].unique()}')\n",
    "print(audio_df_exploded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = tsne_calc(audio_df_exploded, mfcc_matrix, MODELS_METRICS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe20307",
   "metadata": {},
   "source": [
    "## Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_CACHE_DIR = os.path.join(\"data_cache\", \"CNN\")\n",
    "\n",
    "PATIENCE = 3\n",
    "TO_TRAIN = True\n",
    "FROM_START = True\n",
    "if not os.path.exists(MODELS_METRICS_DIR):\n",
    "    os.makedirs(MODELS_METRICS_DIR)\n",
    "\n",
    "split_perc = {'train': 0.8, 'val': 0.2}\n",
    "count_df = get_file_count(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ca453a",
   "metadata": {},
   "source": [
    "Training della CNN classica con le classi che contengono piÃ¹ di 1000 sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ec4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_classes_1000, _ = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (0, 0), subfolder='23-09_training_01', from_start=False, to_train=TO_TRAIN, cardinality=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba605c51",
   "metadata": {},
   "source": [
    "Si ripete il training aggiungendo 10 classi per volta in ordine decrescente in numero di sample contenuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7fbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fino a classe 23\n",
    "n_classes_plus_10, _ = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (n_classes_1000, 10), subfolder='23-09_training_02', from_start=False,to_train=TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582c5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fino a classe 33\n",
    "n_classes_plus_20, _ = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (n_classes_plus_10, 10), subfolder='23-09_training_03', from_start=FROM_START, to_train=TO_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaab8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fino a classe 43\n",
    "n_classes_plus_30, _ = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (n_classes_plus_20, 10), subfolder='23-09_training_04', from_start=FROM_START, to_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fino all'ultima classe\n",
    "n_classes_plus_rem, _ = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (n_classes_plus_30, 10), subfolder='23-09_training_05', from_start=FROM_START, to_train=TO_TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a359d3",
   "metadata": {},
   "source": [
    "## Output Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2bb6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_training_date = '13-10'\n",
    "\n",
    "process_metrics(count_df, 13, os.path.join(MODELS_METRICS_DIR, f'{curr_training_date}_training'), MODELS_METRICS_DIR)\n",
    "process_metrics(count_df, 23, os.path.join(MODELS_METRICS_DIR, f'{curr_training_date}_training'), MODELS_METRICS_DIR)\n",
    "process_metrics(count_df, 33, os.path.join(MODELS_METRICS_DIR, f'{curr_training_date}_training'), MODELS_METRICS_DIR)\n",
    "process_metrics(count_df, 43, os.path.join(MODELS_METRICS_DIR, f'{curr_training_date}_training'), MODELS_METRICS_DIR)\n",
    "process_metrics(count_df, 51, os.path.join(MODELS_METRICS_DIR, f'{curr_training_date}_training'), MODELS_METRICS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2f4c4",
   "metadata": {},
   "source": [
    "## Training delle prime 23 classi + classe altro\n",
    "(tot files 87757)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df_truncated = get_file_count(DATA_DIR)\n",
    "count_df_truncated = count_df_truncated[count_df_truncated['file_count'] < 999]\n",
    "other_species_list = count_df_truncated['species'].tolist()\n",
    "print(f'Other total files: {count_df_truncated[\"file_count\"].sum()}, species count: {count_df_truncated.shape}, species: {other_species_list}')\n",
    "get_other_class(DATA_DIR, other_species_list)\n",
    "count_df = get_file_count(DATA_DIR)\n",
    "print(count_df) \n",
    "other_ds, _ = train_routine(count_df, PATIENCE, SPLIT_PERC, DATA_DIR, (w, h), (0, 0), cardinality=1000, subfolder='13-10_training', from_start=FROM_START, to_train=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c690e6cc",
   "metadata": {},
   "source": [
    "## Old output plots\n",
    "(valido per il training fino al 16-09 incluso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329865ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_metrics(row, all_classes_df, metrics_list):\n",
    "    for metric in metrics_list:\n",
    "        class_num = row['index']\n",
    "        col_name = rf'{class_num}_{metric}'\n",
    "        class_metrics = all_classes_df[col_name]\n",
    "        row[metric] = class_metrics\n",
    "    return row\n",
    "\n",
    "def process_metrics(n_classes, training_date):\n",
    "    all_classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, f'{training_date}_training', f'{n_classes}_CNN_metrics.csv'))\n",
    "    all_classes_df = all_classes_df.loc[:, all_classes_df.columns.str.match(r'^\\d')]\n",
    "    last_epoch_metrics = all_classes_df.iloc[-1]\n",
    "\n",
    "    classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, f'{training_date}_training', f'{n_classes}_label_to_index.csv'))\n",
    "\n",
    "    metrics_list = ['precision', 'recall', 'f1-score', 'support']\n",
    "    classes_df = classes_df.apply(get_class_metrics, axis=1, all_classes_df=last_epoch_metrics, metrics_list=metrics_list)\n",
    "    classes_df['label'] = classes_df['label'].apply(lambda x: ' '.join(x.split(' ')[:2]) if len(x) > 20 else x)\n",
    "    classes_df.to_csv(os.path.join(MODELS_METRICS_DIR, f'{training_date}_merged_metrics', f'{n_classes}_merged_metrics.csv'), index=False)\n",
    "\n",
    "def metrics_plot_builder(metrics_df):\n",
    "    metrics_list = ['precision', 'recall', 'f1-score']\n",
    "    f = 1\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    for metric in metrics_list:\n",
    "        axs = plt.subplot(2, 2, f)\n",
    "        axs.bar(metrics_df['label'], metrics_df[metric], color=\"#87CEEB\")\n",
    "        for i, (metric_value, support) in enumerate(zip(metrics_df[metric], metrics_df['support'])):\n",
    "            label_pos = metric_value - (metric_value/2) if metric_value > 0 else metric_value + 0.02\n",
    "            plt.text(i, label_pos, f'n:{int(support)}', ha='center', va='bottom', fontsize=9, rotation=90)\n",
    "        axs.set_xlabel('Class')\n",
    "        axs.tick_params(axis='x', rotation=90)\n",
    "        axs.set_ylabel(metric.capitalize())\n",
    "        axs.set_title(f'{metric.capitalize()} per Class (ordered by Support - descending)')\n",
    "        \n",
    "        f += 1\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb394bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_training_date = '16-09'\n",
    "process_metrics(13, curr_training_date)\n",
    "#process_metrics(n_classes_plus_10, curr_training_date)\n",
    "#process_metrics(n_classes_plus_20, curr_training_date)\n",
    "#process_metrics(n_classes_plus_30, curr_training_date)\n",
    "#process_metrics(n_classes_plus_rem, curr_training_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fff08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_metrics_date = '16-09_merged_metrics'\n",
    "classes_df = pd.read_csv(os.path.join(MODELS_METRICS_DIR, curr_metrics_date, f'{13}_merged_metrics.csv'))\n",
    "classes_df_sorted = classes_df.sort_values(by='support', ascending=False)\n",
    "fig = metrics_plot_builder(classes_df_sorted)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e078982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
